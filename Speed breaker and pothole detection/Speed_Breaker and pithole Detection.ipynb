{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1AG6wLRMfydEJvdTOD-daYbzgJ5tI0C-Z","timestamp":1666507754872}],"collapsed_sections":[],"authorship_tag":"ABX9TyNqm8e+scr89PEnh/75/XB6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZD4F7ejdXwXp","executionInfo":{"status":"ok","timestamp":1666487160451,"user_tz":-330,"elapsed":1620,"user":{"displayName":"Sai Teja","userId":"13597999912404387741"}},"outputId":"22b7d1e9-4a94-427f-95e9-aec4080ab84e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 14379, done.\u001b[K\n","remote: Total 14379 (delta 0), reused 0 (delta 0), pack-reused 14379\u001b[K\n","Receiving objects: 100% (14379/14379), 13.32 MiB | 32.56 MiB/s, done.\n","Resolving deltas: 100% (9955/9955), done.\n"]}],"source":["!git clone https://github.com/ultralytics/yolov5"]},{"cell_type":"code","source":["\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/"],"metadata":{"id":"1o-5ow6ZXyFb","executionInfo":{"status":"ok","timestamp":1666487222541,"user_tz":-330,"elapsed":489,"user":{"displayName":"Sai Teja","userId":"13597999912404387741"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bJ5FYd8sYINT","executionInfo":{"status":"ok","timestamp":1666487209827,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sai Teja","userId":"13597999912404387741"}},"outputId":"a3f3693e-4b0a-4153-9bbc-e9ec4dc1520c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/\n"]}]},{"cell_type":"code","source":["%cd content\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_590EkpNYMjB","executionInfo":{"status":"ok","timestamp":1666487218942,"user_tz":-330,"elapsed":17,"user":{"displayName":"Sai Teja","userId":"13597999912404387741"}},"outputId":"30e9e1b4-93e0-4be8-95fe-512644a6e5da"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["!kaggle datasets download -d saktheeswaranswan/yolov5-speed-breaker-detection-driver-alert-system"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h6VWYuDwYO3V","executionInfo":{"status":"ok","timestamp":1666487253245,"user_tz":-330,"elapsed":9199,"user":{"displayName":"Sai Teja","userId":"13597999912404387741"}},"outputId":"c210cd3e-c5a1-4a08-8985-8bbcf372a9bc"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n","Downloading yolov5-speed-breaker-detection-driver-alert-system.zip to /content\n","100% 868M/872M [00:08<00:00, 106MB/s]\n","100% 872M/872M [00:08<00:00, 111MB/s]\n"]}]},{"cell_type":"code","source":["import zipfile\n","zip_ref = zipfile.ZipFile('/content/yolov5-speed-breaker-detection-driver-alert-system.zip', 'r')\n","zip_ref.extractall('/content')\n","zip_ref.close()"],"metadata":{"id":"YZlQc8xDYU_3","executionInfo":{"status":"ok","timestamp":1666487259011,"user_tz":-330,"elapsed":5770,"user":{"displayName":"Sai Teja","userId":"13597999912404387741"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7c9Q3njZYZc7","executionInfo":{"status":"ok","timestamp":1666487309584,"user_tz":-330,"elapsed":20,"user":{"displayName":"Sai Teja","userId":"13597999912404387741"}},"outputId":"7c8552bb-51fe-4281-d312-b19ba3a2e006"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov5\n"]}]},{"cell_type":"code","source":["%cat /content/data.yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50uvOulCYlCo","executionInfo":{"status":"ok","timestamp":1666487327811,"user_tz":-330,"elapsed":9,"user":{"displayName":"Sai Teja","userId":"13597999912404387741"}},"outputId":"12f317e7-d6d0-44f7-d208-d6f59831f0ac"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["train: ../train/images\n","val: ../valid/images\n","\n","nc: 1\n","names: ['speed_breaker_alert']"]}]},{"cell_type":"code","source":["import yaml\n","with open(\"/content/data.yaml\", 'r') as stream:\n","    num_classes = str(yaml.safe_load(stream))"],"metadata":{"id":"mAJRDiAOYphU","executionInfo":{"status":"ok","timestamp":1666487339519,"user_tz":-330,"elapsed":638,"user":{"displayName":"Sai Teja","userId":"13597999912404387741"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["%cat /content/yolov5/models/yolov5m.yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fBMPa4ZgYsQG","executionInfo":{"status":"ok","timestamp":1666487346348,"user_tz":-330,"elapsed":13,"user":{"displayName":"Sai Teja","userId":"13597999912404387741"}},"outputId":"8a0f1be5-72b5-47e9-ec82-a7650176cf01"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["# YOLOv5 ðŸš€ by Ultralytics, GPL-3.0 license\n","\n","# Parameters\n","nc: 80  # number of classes\n","depth_multiple: 0.67  # model depth multiple\n","width_multiple: 0.75  # layer channel multiple\n","anchors:\n","  - [10,13, 16,30, 33,23]  # P3/8\n","  - [30,61, 62,45, 59,119]  # P4/16\n","  - [116,90, 156,198, 373,326]  # P5/32\n","\n","# YOLOv5 v6.0 backbone\n","backbone:\n","  # [from, number, module, args]\n","  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n","   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n","   [-1, 3, C3, [128]],\n","   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n","   [-1, 6, C3, [256]],\n","   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n","   [-1, 9, C3, [512]],\n","   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n","   [-1, 3, C3, [1024]],\n","   [-1, 1, SPPF, [1024, 5]],  # 9\n","  ]\n","\n","# YOLOv5 v6.0 head\n","head:\n","  [[-1, 1, Conv, [512, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n","   [-1, 3, C3, [512, False]],  # 13\n","\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n","   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n","\n","   [-1, 1, Conv, [256, 3, 2]],\n","   [[-1, 14], 1, Concat, [1]],  # cat head P4\n","   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n","\n","   [-1, 1, Conv, [512, 3, 2]],\n","   [[-1, 10], 1, Concat, [1]],  # cat head P5\n","   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n","\n","   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n","  ]\n"]}]},{"cell_type":"code","source":["from IPython.core.magic import register_line_cell_magic\n","\n","@register_line_cell_magic\n","def writetemplate(line, cell):\n","    with open(line, 'w') as f:\n","        f.write(cell.format(**globals()))\n","\n"],"metadata":{"id":"8numXa_8Y9gm","executionInfo":{"status":"ok","timestamp":1666487420218,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sai Teja","userId":"13597999912404387741"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["%%writetemplate /content/yolov5/models/custom_yolov5m.yaml\n","# parameters\n","nc: {num_classes}  # number of classes\n","depth_multiple: 0.67  # model depth multiple\n","width_multiple: 0.75  # layer channel multiple\n","\n","# anchors\n","anchors:\n","  - [10,13, 16,30, 33,23]  # P3/8\n","  - [30,61, 62,45, 59,119]  # P4/16\n","  - [116,90, 156,198, 373,326]  # P5/32\n","\n","# YOLOv5 backbone\n","backbone:\n","  # [from, number, module, args]\n","  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n","   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n","   [-1, 3, C3, [128]],\n","   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n","   [-1, 9, C3, [256]],\n","   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n","   [-1, 9, C3, [512]],\n","   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n","   [-1, 1, SPP, [1024, [5, 9, 13]]],\n","   [-1, 3, C3, [1024, False]],  # 9\n","  ]\n","\n","# YOLOv5 head\n","head:\n","  [[-1, 1, Conv, [512, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n","   [-1, 3, C3, [512, False]],  # 13\n","\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n","   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n","\n","   [-1, 1, Conv, [256, 3, 2]],\n","   [[-1, 14], 1, Concat, [1]],  # cat head P4\n","   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n","\n","   [-1, 1, Conv, [512, 3, 2]],\n","   [[-1, 10], 1, Concat, [1]],  # cat head P5\n","   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n","\n","   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n","  ]"],"metadata":{"id":"HEyQDOCfYt-i","executionInfo":{"status":"ok","timestamp":1666487434777,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sai Teja","userId":"13597999912404387741"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["!cat /content/dataspeed/data.yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HkgUll7NYyru","executionInfo":{"status":"ok","timestamp":1666487444602,"user_tz":-330,"elapsed":12,"user":{"displayName":"Sai Teja","userId":"13597999912404387741"}},"outputId":"a3d12aee-ff80-469a-d161-15df3b5511f7"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["train: ../train/images\n","val: ../valid/images\n","\n","nc: 1\n","names: ['speed_breaker_alert']"]}]},{"cell_type":"code","source":["%cd /content/yolov5\n","!cat /content/dataspeed/data.yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VC3nU2jOZF44","executionInfo":{"status":"ok","timestamp":1666487452565,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sai Teja","userId":"13597999912404387741"}},"outputId":"e2e3e185-4c2b-4629-a460-7217bac64fee"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov5\n","train: ../train/images\n","val: ../valid/images\n","\n","nc: 1\n","names: ['speed_breaker_alert']"]}]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E9RdvPGJZH46","executionInfo":{"status":"ok","timestamp":1666487455801,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sai Teja","userId":"13597999912404387741"}},"outputId":"85682aaa-6d8d-410d-a9b8-7bba23277fcd"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov5\n"]}]},{"cell_type":"code","source":["%%time\n","%cd /content/yolov5\n","!python train.py --img 416 --batch 16 --epochs 20 --data '/content/dataspeed/data.yaml' --cfg /content/yolov5/models/custom_yolov5m.yaml --weights '' --name yolov5m_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XHltlZpsZImh","executionInfo":{"status":"ok","timestamp":1666492517844,"user_tz":-330,"elapsed":4987588,"user":{"displayName":"Sai Teja","userId":"13597999912404387741"}},"outputId":"b3de0037-0498-4688-ee48-59e41cd4056a"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov5\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=/content/yolov5/models/custom_yolov5m.yaml, data=/content/dataspeed/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5m_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n","YOLOv5 ðŸš€ v6.2-205-geef9057 Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ðŸš€ in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00<00:00, 27.6MB/s]\n","Overriding model.yaml nc={'train': '../train/images', 'val': '../valid/images', 'nc': 1, 'names': ['speed_breaker_alert']} with nc=1\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      5280  models.common.Focus                     [3, 48, 3]                    \n","  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n","  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n","  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n","  4                -1  6    629760  models.common.C3                        [192, 192, 6]                 \n","  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n","  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n","  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n","  8                -1  1   1476864  models.common.SPP                       [768, 768, [5, 9, 13]]        \n","  9                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n"," 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n"," 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n"," 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n"," 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n"," 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n","custom_YOLOv5m summary: 309 layers, 21056406 parameters, 21056406 gradients\n","\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 83 weight(decay=0.0), 86 weight(decay=0.0005), 86 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/dataspeed/data/train/labels' images and labels...2723 found, 0 missing, 14 empty, 0 corrupt: 100% 2723/2723 [00:01<00:00, 2069.05it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataspeed/data/train/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/dataspeed/data/val/labels' images and labels...303 found, 0 missing, 1 empty, 0 corrupt: 100% 303/303 [00:00<00:00, 1015.38it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataspeed/data/val/labels.cache\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.37 anchors/target, 0.953 Best Possible Recall (BPR). Anchors are a poor fit to dataset âš ï¸, attempting to improve...\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING âš ï¸ Extremely small objects found: 4 of 4842 labels are <3 pixels in size\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 4842 points...\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7829: 100% 1000/1000 [00:05<00:00, 191.50it/s]\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9983 best possible recall, 5.93 anchors past thr\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.398/0.783-mean/best, past_thr=0.532-mean: 25,11, 70,17, 177,16, 182,28, 315,25, 203,43, 293,40, 381,50, 397,94\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone âœ… (optional: update model *.yaml to use these anchors in the future)\n","Plotting labels to runs/train/yolov5m_results2/labels.jpg... \n","Image sizes 416 train, 416 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/yolov5m_results2\u001b[0m\n","Starting training for 20 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       0/19      2.98G     0.1009    0.03349          0         10        416: 100% 171/171 [04:00<00:00,  1.41s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:12<00:00,  1.21s/it]\n","                   all        303        548    0.00239     0.0237     0.0017    0.00043\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       1/19      3.22G    0.09533     0.0355          0         12        416: 100% 171/171 [03:55<00:00,  1.37s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:11<00:00,  1.12s/it]\n","                   all        303        548     0.0237     0.0128    0.00322   0.000712\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       2/19      3.22G    0.08828     0.0374          0         15        416: 100% 171/171 [03:53<00:00,  1.37s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:10<00:00,  1.07s/it]\n","                   all        303        548     0.0495     0.0712     0.0131    0.00232\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       3/19      3.22G    0.07734    0.03778          0         14        416: 100% 171/171 [03:52<00:00,  1.36s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:10<00:00,  1.09s/it]\n","                   all        303        548       0.18      0.266     0.0907     0.0212\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       4/19      3.22G    0.06932    0.03439          0         12        416: 100% 171/171 [03:53<00:00,  1.36s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:10<00:00,  1.05s/it]\n","                   all        303        548      0.446      0.341      0.324      0.114\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       5/19      3.22G    0.06082    0.03052          0         18        416: 100% 171/171 [03:53<00:00,  1.36s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:10<00:00,  1.06s/it]\n","                   all        303        548       0.76      0.564      0.652      0.255\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       6/19      3.22G    0.05617    0.02842          0          5        416: 100% 171/171 [03:52<00:00,  1.36s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:10<00:00,  1.05s/it]\n","                   all        303        548      0.717      0.569      0.586      0.236\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       7/19      3.22G    0.05191    0.02676          0         12        416: 100% 171/171 [03:52<00:00,  1.36s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:10<00:00,  1.07s/it]\n","                   all        303        548       0.85      0.699       0.78      0.358\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       8/19      3.22G    0.04883    0.02502          0         14        416: 100% 171/171 [03:53<00:00,  1.36s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:10<00:00,  1.04s/it]\n","                   all        303        548      0.857      0.704      0.787      0.377\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       9/19      3.22G    0.04597    0.02365          0         20        416: 100% 171/171 [03:52<00:00,  1.36s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:10<00:00,  1.06s/it]\n","                   all        303        548      0.866      0.765      0.846      0.446\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      10/19      3.22G    0.04364    0.02295          0          8        416: 100% 171/171 [03:51<00:00,  1.35s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:10<00:00,  1.06s/it]\n","                   all        303        548      0.919      0.799      0.868      0.486\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      11/19      3.22G    0.04193    0.02176          0         17        416: 100% 171/171 [03:51<00:00,  1.36s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:11<00:00,  1.13s/it]\n","                   all        303        548      0.914      0.734      0.827      0.438\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      12/19      3.22G    0.04045    0.02106          0         15        416: 100% 171/171 [03:54<00:00,  1.37s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:10<00:00,  1.05s/it]\n","                   all        303        548      0.872      0.821      0.882        0.5\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      13/19      3.22G    0.03848     0.0205          0         14        416: 100% 171/171 [03:55<00:00,  1.38s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:10<00:00,  1.05s/it]\n","                   all        303        548      0.907      0.799      0.886      0.487\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      14/19      3.22G    0.03711    0.02042          0         12        416: 100% 171/171 [03:53<00:00,  1.36s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:10<00:00,  1.06s/it]\n","                   all        303        548       0.93      0.799       0.89      0.514\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      15/19      3.22G    0.03563    0.01949          0         13        416: 100% 171/171 [03:53<00:00,  1.36s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:10<00:00,  1.04s/it]\n","                   all        303        548      0.914      0.794      0.869      0.505\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      16/19      3.22G    0.03493    0.01899          0          9        416: 100% 171/171 [03:53<00:00,  1.37s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:10<00:00,  1.05s/it]\n","                   all        303        548      0.921       0.85      0.911      0.591\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      17/19      3.22G    0.03413    0.01852          0         11        416: 100% 171/171 [03:52<00:00,  1.36s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:10<00:00,  1.06s/it]\n","                   all        303        548      0.937      0.845      0.919      0.598\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      18/19      3.22G    0.03263    0.01798          0          6        416: 100% 171/171 [03:53<00:00,  1.37s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:10<00:00,  1.06s/it]\n","                   all        303        548      0.922       0.86      0.925      0.611\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      19/19      3.22G    0.03218    0.01792          0         14        416: 100% 171/171 [03:51<00:00,  1.36s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:10<00:00,  1.08s/it]\n","                   all        303        548      0.933      0.865      0.929      0.625\n","\n","20 epochs completed in 1.369 hours.\n","Optimizer stripped from runs/train/yolov5m_results2/weights/last.pt, 42.5MB\n","Optimizer stripped from runs/train/yolov5m_results2/weights/best.pt, 42.5MB\n","\n","Validating runs/train/yolov5m_results2/weights/best.pt...\n","Fusing layers... \n","custom_YOLOv5m summary: 226 layers, 21037638 parameters, 0 gradients\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:08<00:00,  1.22it/s]\n","                   all        303        548      0.931      0.865      0.929      0.625\n","Results saved to \u001b[1mruns/train/yolov5m_results2\u001b[0m\n","CPU times: user 33.6 s, sys: 4.12 s, total: 37.7 s\n","Wall time: 1h 23min 7s\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"BEzlqr6_ZMYh"},"execution_count":null,"outputs":[]}]}